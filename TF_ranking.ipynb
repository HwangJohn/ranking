{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-ranking.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "DwZbuwtxoAzD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### https://github.com/tensorflow/ranking\n",
        "\n",
        "블로그 : https://ai.googleblog.com/2018/12/tf-ranking-scalable-tensorflow-library.html"
      ]
    },
    {
      "metadata": {
        "id": "77RHdyJQWkPO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "b8a78f9e-09a5-47f9-e2f2-4e89ec4cf530"
      },
      "cell_type": "code",
      "source": [
        "# code download\n",
        "!git clone https://github.com/tensorflow/ranking.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ranking'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 68 (delta 22), reused 54 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YCF4wk0da5iA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## bazel install for building tf-ranking package\n",
        "\n",
        "https://stackoverflow.com/questions/45767275/unable-to-install-bazel-on-ubuntu-14-04-using-apt-get 참조\n"
      ]
    },
    {
      "metadata": {
        "id": "_eGTxyusXLx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "ab1ead7a-1274-4912-91c6-f2591cdbfc1b"
      },
      "cell_type": "code",
      "source": [
        "# install bazel\n",
        "!apt-get install pkg-config zip g++ zlib1g-dev unzip python\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/0.20.0/bazel-0.20.0-installer-linux-x86_64.sh\n",
        "!chmod +x bazel-0.20.0-installer-linux-x86_64.sh\n",
        "!./bazel-0.20.0-installer-linux-x86_64.sh --user"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu2).\n",
            "python is already the newest version (2.7.15~rc1-1).\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "zip is already the newest version (3.0-11build1).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "zlib1g-dev set to manually installed.\n",
            "g++ is already the newest version (4:7.3.0-3ubuntu2.1).\n",
            "g++ set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PtRTbi9GahZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "5be20956-7435-4586-b740-5489b72f2096"
      },
      "cell_type": "code",
      "source": [
        "# building tf-ranking package\n",
        "import os\n",
        "os.environ['PATH']\n",
        "os.environ['PATH'] = os.environ['PATH']+\":$HOME/bin\"\n",
        "!export PATH=\"$PATH:$HOME/bin\"\n",
        "!apt-get install python-pip\n",
        "\n",
        "!cd ranking  && $HOME/bin/bazel build /tensorflow_ranking/tools/pip_package:build_pip_package\n",
        "!cd ranking  && tensorflow_ranking/tools/pip_package/build_pip_package.sh /tmp/ranking_pip\n",
        "!pip install /tmp/ranking_pip/tensorflow_ranking*.whl"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "BWPIAhpmbrPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2536
        },
        "outputId": "de0986bb-9b2c-47ea-96ef-e0a14b68ef59"
      },
      "cell_type": "code",
      "source": [
        "# test after installing tf-ranking package\n",
        "!cd ranking && /root/bin/bazel test //tensorflow_ranking/..."
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: \u001b[0mInvocation ID: 55fef6c4-2131-4f2b-b06e-b8fc86186a10\n",
            "\u001b[32mLoading:\u001b[0m \n",
            "\r\u001b[1A\u001b[K\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
            "\r\u001b[1A\u001b[K\u001b[32mAnalyzing:\u001b[0m 21 targets (1 packages loaded, 0 targets configured)\n",
            "\r\u001b[1A\u001b[K\u001b[32mAnalyzing:\u001b[0m 21 targets (5 packages loaded, 31 targets configured)\n",
            "\u001b[32mINFO: \u001b[0mAnalysed 21 targets (7 packages loaded, 181 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 13 targets and 8 test targets...\n",
            "\u001b[32m[13 / 15]\u001b[0m 2 actions running\n",
            "    Testing //.../python:feature_test; 0s processwrapper-sandbox\n",
            "\u001b[32m[13 / 15]\u001b[0m 2 actions running\n",
            "    Testing //.../python:feature_test; 1s processwrapper-sandbox\n",
            "\u001b[32m[13 / 15]\u001b[0m 2 actions running\n",
            "    Testing //.../python:feature_test; 2s processwrapper-sandbox\n",
            "\u001b[32m[13 / 15]\u001b[0m 2 actions running\n",
            "    Testing //.../python:feature_test; 3s processwrapper-sandbox\n",
            "\u001b[32m[17 / 19]\u001b[0m 1 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:utils_test\u001b[0m\n",
            "    Testing //.../python:feature_test; 3s processwrapper-sandbox\n",
            "\u001b[32m[17 / 19]\u001b[0m 1 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:utils_test\u001b[0m\n",
            "    Testing //.../python:feature_test; 3s processwrapper-sandbox\n",
            "\u001b[32m[17 / 19]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:feature_test; 3s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 0s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 1s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 2s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 3s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 4s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 5s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 6s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 7s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 8s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 9s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 10s processwrapper-sandbox\n",
            "\u001b[32m[18 / 20]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 11s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions, 1 running\u001b[0m; last test: \u001b[32m...python:metrics_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 0s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 0s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 1s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 2s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 3s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 4s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 5s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 6s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 7s processwrapper-sandbox\n",
            "\u001b[32m[26 / 28]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 7s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 8s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 9s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 10s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 11s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 12s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 13s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 14s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 15s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 16s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 17s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 18s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 19s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 19s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 20s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 21s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 22s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 23s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 24s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 25s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 26s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 27s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 28s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 29s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 30s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 31s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 32s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 33s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 34s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 35s processwrapper-sandbox\n",
            "\u001b[32m[34 / 36]\u001b[0m 6 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:losses_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 35s processwrapper-sandbox\n",
            "\u001b[32m[35 / 36]\u001b[0m 7 / 8 tests;\u001b[0m  1 action\u001b[0m; last test: \u001b[32m...xamples:tf_ranking_libsvm_test\u001b[0m\u001b[0m\n",
            "\u001b[32m[35 / 36]\u001b[0m 7 / 8 tests;\u001b[0m  1 action\u001b[0m; last test: \u001b[32m...xamples:tf_ranking_libsvm_test\u001b[0m\u001b[0m\n",
            "\u001b[32m[35 / 36]\u001b[0m 7 / 8 tests;\u001b[0m  1 action\u001b[0m; last test: \u001b[32m...xamples:tf_ranking_libsvm_test\u001b[0m\u001b[0m\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 54.013s, Critical Path: 35.84s\n",
            "\u001b[32mINFO: \u001b[0m8 processes: 8 processwrapper-sandbox.\n",
            "\u001b[32mINFO:\u001b[0m Build completed successfully, 36 total actions\n",
            "//tensorflow_ranking/examples:tf_ranking_libsvm_test                     \u001b[0m\u001b[32mPASSED\u001b[0m in 35.8s\n",
            "//tensorflow_ranking/python:data_test                                    \u001b[0m\u001b[32mPASSED\u001b[0m in 7.7s\n",
            "//tensorflow_ranking/python:feature_test                                 \u001b[0m\u001b[32mPASSED\u001b[0m in 3.9s\n",
            "//tensorflow_ranking/python:head_test                                    \u001b[0m\u001b[32mPASSED\u001b[0m in 2.4s\n",
            "//tensorflow_ranking/python:losses_test                                  \u001b[0m\u001b[32mPASSED\u001b[0m in 27.6s\n",
            "//tensorflow_ranking/python:metrics_test                                 \u001b[0m\u001b[32mPASSED\u001b[0m in 11.5s\n",
            "//tensorflow_ranking/python:model_test                                   \u001b[0m\u001b[32mPASSED\u001b[0m in 10.7s\n",
            "//tensorflow_ranking/python:utils_test                                   \u001b[0m\u001b[32mPASSED\u001b[0m in 3.2s\n",
            "\n",
            "Executed 8 out of 8 tests: 8 tests pass.\n",
            "\u001b[32mINFO:\u001b[0m Build completed successfully, 36 total actions\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gzQRTlN_eUiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python -c \"import tensorflow_ranking\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lEyf-VNFLg93",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train test"
      ]
    },
    {
      "metadata": {
        "id": "eZ5spDZdeZ1l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.environ['OUTPUT_DIR']=\"/tmp/output\"\n",
        "os.environ['TRAIN']=\"ranking/tensorflow_ranking/examples/data/train.txt\"\n",
        "os.environ['VALI']=\"ranking/tensorflow_ranking/examples/data/vali.txt \"\n",
        "os.environ['TEST']=\"ranking/tensorflow_ranking/examples/data/test.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i0SJYOXOheU1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf $OUTPUT_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vuFE8M4jgEoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "1fd3b43c-6836-4a76-aef5-4387578140be"
      },
      "cell_type": "code",
      "source": [
        "!/root/bin/bazel build -c opt ranking/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "ERROR: The 'build' command is only supported from within a workspace.\n",
            "WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\n",
            "INFO: Invocation ID: 6de02bb4-dd02-45ad-97c1-e477fa783a4b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cg0B0LCPhqy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1076
        },
        "outputId": "4a237c39-f706-4689-973b-c43f418d10f8"
      },
      "cell_type": "code",
      "source": [
        "!ranking/bazel-bin/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary \\\n",
        "  --train_path=$TRAIN \\\n",
        "  --vali_path=$VALI \\\n",
        "  --test_path=$TEST \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --num_features=136 \\\n",
        "  --num_train_steps=100"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loading data from ranking/tensorflow_ranking/examples/data/train.txt\n",
            "INFO:tensorflow:Number of queries: 27\n",
            "INFO:tensorflow:Number of documents in total: 119\n",
            "INFO:tensorflow:Number of documents discarded: 0\n",
            "INFO:tensorflow:Loading data from ranking/tensorflow_ranking/examples/data/vali.txt\n",
            "INFO:tensorflow:Number of queries: 9\n",
            "INFO:tensorflow:Number of documents in total: 36\n",
            "INFO:tensorflow:Number of documents discarded: 0\n",
            "INFO:tensorflow:Loading data from ranking/tensorflow_ranking/examples/data/test.txt\n",
            "INFO:tensorflow:Number of queries: 9\n",
            "INFO:tensorflow:Number of documents in total: 36\n",
            "INFO:tensorflow:Number of documents discarded: 0\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faf9ccfba90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function make_groupwise_ranking_fn.<locals>._model_fn at 0x7faf9cd01048>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/output/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.2190515, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 100 into /tmp/output/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-12-07-02:38:07\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/output/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/1]\n",
            "INFO:tensorflow:Finished evaluation at 2018-12-07-02:38:08\n",
            "INFO:tensorflow:Saving dict for global step 100: global_step = 100, labels_mean = 0.7777778, logits_mean = 0.19107744, loss = 1.0040835, metric/arp = 3.7142856, metric/ndcg@1 = 0.3703704, metric/ndcg@10 = 0.7371514, metric/ndcg@3 = 0.58184433, metric/ndcg@5 = 0.69914955, metric/ordered_pair_accuracy = 0.3220339\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/output/model.ckpt-100\n",
            "INFO:tensorflow:Loss for final step: 0.03390577.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-12-07-02:38:12\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/output/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-12-07-02:38:14\n",
            "INFO:tensorflow:Saving dict for global step 100: global_step = 100, labels_mean = 0.7777778, logits_mean = 0.19107744, loss = 1.0040835, metric/arp = 3.7142856, metric/ndcg@1 = 0.3703704, metric/ndcg@10 = 0.7371514, metric/ndcg@3 = 0.58184433, metric/ndcg@5 = 0.69914955, metric/ordered_pair_accuracy = 0.3220339\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/output/model.ckpt-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IrhGlyFxqBAZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook example practice"
      ]
    },
    {
      "metadata": {
        "id": "sOxgfUIQjEPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "32c252b8-4fad-4606-d415-fc964fcde7d9"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_ranking as tfr\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.executing_eagerly()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "1evfHk4XqLlW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we will define some global parameters."
      ]
    },
    {
      "metadata": {
        "id": "iuQwhiLjqJSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store the paths to files containing training and test instances.\n",
        "# As noted above, we will assume the data is in the LibSVM format\n",
        "# and that the content of each file is sorted by query ID.\n",
        "\n",
        "# file path : ranking/tensorflow_ranking/examples\n",
        "\n",
        "_TRAIN_DATA_PATH=\"ranking/tensorflow_ranking/examples/data/train.txt\"\n",
        "_TEST_DATA_PATH=\"ranking/tensorflow_ranking/examples/data/test.txt\"\n",
        "\n",
        "# Define a loss function. To find a complete list of available\n",
        "# loss functions or to learn how to add your own custom function\n",
        "# please refer to the tensorflow_ranking.losses module.\n",
        "_LOSS=\"pairwise_logistic_loss\"\n",
        "\n",
        "# In the TF-Ranking framework, a training instance is represented\n",
        "# by a Tensor that contains features from a list of documents\n",
        "# associated with a single query. For simplicity, we fix the shape\n",
        "# of these Tensors to a maximum list size and call it \"list_size,\"\n",
        "# the maximum number of documents per query in the dataset.\n",
        "# In this demo, we take the following approach:\n",
        "#   * If a query has fewer documents, its Tensor will be padded\n",
        "#     appropriately.\n",
        "#   * If a query has more documents, we shuffle its list of\n",
        "#     documents and trim the list down to the prescribed list_size.\n",
        "_LIST_SIZE=100\n",
        "\n",
        "# The total number of features per query-document pair.\n",
        "# We set this number to the number of features in the MSLR-Web30K\n",
        "# dataset.\n",
        "_NUM_FEATURES=136\n",
        "\n",
        "# Parameters to the scoring function.\n",
        "_BATCH_SIZE=32\n",
        "_HIDDEN_LAYER_DIMS=[\"20\", \"10\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfX9601xsHez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input Pipeline\n",
        "\n",
        "첫 번째 단계는 데이터 집합을 읽는 입력 파이프 라인을 만들고 tensorflow.data.Dataset 개체를 생성합니다. 이 예제에서는 주어진 파일에서 Dataset을 생성하기 위해 tensorflow_ranking.data 모듈에 포함 된 LibSVM 파서를 호출합니다.\n",
        "\n",
        "이 함수를 경로 인수로 매개 변수화하여 함수가 학습 및 테스트 데이터 파일을 읽는 데 사용될 수 있도록합니다."
      ]
    },
    {
      "metadata": {
        "id": "0egAEH5msGZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn(path):\n",
        "  train_dataset = tf.data.Dataset.from_generator(\n",
        "      tfr.data.libsvm_generator(path, _NUM_FEATURES, _LIST_SIZE),\n",
        "      output_types=(\n",
        "          {str(k): tf.float32 for k in range(1,_NUM_FEATURES+1)},\n",
        "          tf.float32\n",
        "      ),\n",
        "      output_shapes=(\n",
        "          {str(k): tf.TensorShape([_LIST_SIZE, 1])\n",
        "            for k in range(1,_NUM_FEATURES+1)},\n",
        "          tf.TensorShape([_LIST_SIZE])\n",
        "      )\n",
        "  )\n",
        "\n",
        "  train_dataset = train_dataset.shuffle(1000).repeat().batch(_BATCH_SIZE)\n",
        "  return train_dataset.make_one_shot_iterator().get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6QkRWZptKcD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Scoring Function\n",
        "\n",
        "다음으로, 우리는 틀림없이 TF 랭킹 모델의 중심에있는 Scoring function 으로 돌아갑니다. 아이디어는 (일련의) 쿼리 - 문서 쌍 (들)에 대한 관련성 점수를 계산하는 것입니다. TF- 랭킹 모델은 훈련 데이터를 사용하여이 기능을 학습합니다.\n",
        "여기에서는 피드 포워드 네트워크를 사용하여 채점 함수를 공식화합니다. 함수는 단일 example (즉, 질의 - 문서 쌍)의 특징을 취하여 관련도를 산출한다."
      ]
    },
    {
      "metadata": {
        "id": "gP4CGFo4tKEh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def example_feature_columns():\n",
        "  \"\"\"Returns the example feature columns.\"\"\"\n",
        "  feature_names = [\n",
        "      \"%d\" % (i+1) for i in range(0, _NUM_FEATURES)\n",
        "  ]\n",
        "  return {\n",
        "      name: tf.feature_column.numeric_column(\n",
        "        name, shape=(1,), default_value=0.0) for name in feature_names\n",
        "  }\n",
        "\n",
        "def make_score_fn():\n",
        "  \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
        "\n",
        "  def _score_fn(context_features, group_features, mode, params, config):\n",
        "    \"\"\"Defines the network to score a documents.\"\"\"\n",
        "    del params\n",
        "    del config\n",
        "    # Define input layer.\n",
        "    example_input = [\n",
        "        tf.layers.flatten(group_features[name])\n",
        "        for name in sorted(example_feature_columns())\n",
        "    ]\n",
        "    input_layer = tf.concat(example_input, 1)\n",
        "\n",
        "    cur_layer = input_layer\n",
        "    for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
        "      cur_layer = tf.layers.dense(\n",
        "          cur_layer,\n",
        "          units=layer_width,\n",
        "          activation=\"tanh\")\n",
        "\n",
        "    logits = tf.layers.dense(cur_layer, units=1)\n",
        "    return logits\n",
        "\n",
        "  return _score_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZTXgBKM3iaA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics\n",
        "\n",
        "우리는 TF 랭킹 라이브러리에서 인기있는 정보 검색 평가 메트릭을 구현했습니다."
      ]
    },
    {
      "metadata": {
        "id": "VHc_8FvitJRX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_metric_fns():\n",
        "  \"\"\"Returns a dict from name to metric functions.\n",
        "\n",
        "  This can be customized as follows. Care must be taken when handling padded\n",
        "  lists.\n",
        "\n",
        "  def _auc(labels, predictions, features):\n",
        "    is_label_valid = tf_reshape(tf.greater_equal(labels, 0.), [-1, 1])\n",
        "    clean_labels = tf.boolean_mask(tf.reshape(labels, [-1, 1], is_label_valid)\n",
        "    clean_pred = tf.boolean_maks(tf.reshape(predictions, [-1, 1], is_label_valid)\n",
        "    return tf.metrics.auc(clean_labels, tf.sigmoid(clean_pred), ...)\n",
        "  metric_fns[\"auc\"] = _auc\n",
        "\n",
        "  Returns:\n",
        "    A dict mapping from metric name to a metric function with above signature.\n",
        "  \"\"\"\n",
        "  metric_fns = {}\n",
        "  metric_fns.update({\n",
        "      \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
        "          tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
        "      for topn in [1, 3, 5, 10]\n",
        "  })\n",
        "\n",
        "  return metric_fns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnQmzk964eEB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Putting It All Together\n",
        "\n",
        "우리는 이제 위의 모든 구성 요소를 함께 모으고 모델을 훈련하고 평가하는 데 사용할 수있는 Estimator를 만들 준비가되었습니다."
      ]
    },
    {
      "metadata": {
        "id": "fkPp6cBj4c9L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_estimator(hparams):\n",
        "  \"\"\"Create a ranking estimator.\n",
        "\n",
        "  Args:\n",
        "    hparams: (tf.contrib.training.HParams) a hyperparameters object.\n",
        "\n",
        "  Returns:\n",
        "    tf.learn `Estimator`.\n",
        "  \"\"\"\n",
        "  def _train_op_fn(loss):\n",
        "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
        "    return tf.contrib.layers.optimize_loss(\n",
        "        loss=loss,\n",
        "        global_step=tf.train.get_global_step(),\n",
        "        learning_rate=hparams.learning_rate,\n",
        "        optimizer=\"Adagrad\")\n",
        "\n",
        "  ranking_head = tfr.head.create_ranking_head(\n",
        "      loss_fn=tfr.losses.make_loss_fn(_LOSS),\n",
        "      eval_metric_fns=eval_metric_fns(),\n",
        "      train_op_fn=_train_op_fn)\n",
        "\n",
        "  return tf.estimator.Estimator(\n",
        "      model_fn=tfr.model.make_groupwise_ranking_fn(\n",
        "          group_score_fn=make_score_fn(),\n",
        "          group_size=1,\n",
        "          transform_fn=None,\n",
        "          ranking_head=ranking_head),\n",
        "      params=hparams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d50zp4i65r6b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "위에 정의한 Estimator를 인스턴스화하고 초기화합니다"
      ]
    },
    {
      "metadata": {
        "id": "M8CV3TCm5rHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "950a8411-0072-4b40-c163-1b761edaa16a"
      },
      "cell_type": "code",
      "source": [
        "hparams = tf.contrib.training.HParams(learning_rate=0.05)\n",
        "ranker = get_estimator(hparams)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpxlbzj587\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpxlbzj587', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3fa22a51d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "91OQL-Zb51hW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3839
        },
        "outputId": "2b0f0e88-e61c-4398-9425-9d8f26e0fbc2"
      },
      "cell_type": "code",
      "source": [
        "ranker.train(input_fn=lambda: input_fn(_TRAIN_DATA_PATH), steps=10000)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpxlbzj587/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpxlbzj587/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.061991654, step = 101\n",
            "INFO:tensorflow:global_step/sec: 5.07503\n",
            "INFO:tensorflow:loss = 0.018773297, step = 201 (19.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.25079\n",
            "INFO:tensorflow:loss = 0.011238843, step = 301 (19.045 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.3784\n",
            "INFO:tensorflow:loss = 0.0074596484, step = 401 (18.591 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.29672\n",
            "INFO:tensorflow:loss = 0.0057899323, step = 501 (18.884 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35089\n",
            "INFO:tensorflow:loss = 0.004536319, step = 601 (18.686 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.328\n",
            "INFO:tensorflow:loss = 0.0037323814, step = 701 (18.770 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36255\n",
            "INFO:tensorflow:loss = 0.002971959, step = 801 (18.646 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35493\n",
            "INFO:tensorflow:loss = 0.00267803, step = 901 (18.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.14646\n",
            "INFO:tensorflow:loss = 0.0020804245, step = 1001 (19.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35923\n",
            "INFO:tensorflow:loss = 0.0020048756, step = 1101 (18.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.42539\n",
            "INFO:tensorflow:loss = 0.0018039803, step = 1201 (18.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36146\n",
            "INFO:tensorflow:loss = 0.0017008912, step = 1301 (18.653 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37862\n",
            "INFO:tensorflow:loss = 0.001416618, step = 1401 (18.590 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.3538\n",
            "INFO:tensorflow:loss = 0.0012396597, step = 1501 (18.681 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.39214\n",
            "INFO:tensorflow:loss = 0.0012524517, step = 1601 (18.545 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.34068\n",
            "INFO:tensorflow:loss = 0.0010839696, step = 1701 (18.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.38382\n",
            "INFO:tensorflow:loss = 0.0011071196, step = 1801 (18.575 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.32504\n",
            "INFO:tensorflow:loss = 0.001097621, step = 1901 (18.778 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.27708\n",
            "INFO:tensorflow:loss = 0.0009914242, step = 2001 (18.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35735\n",
            "INFO:tensorflow:loss = 0.000913855, step = 2101 (18.665 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35564\n",
            "INFO:tensorflow:loss = 0.0008860095, step = 2201 (18.672 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37698\n",
            "INFO:tensorflow:loss = 0.0007740849, step = 2301 (18.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.38979\n",
            "INFO:tensorflow:loss = 0.0007862143, step = 2401 (18.550 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.39566\n",
            "INFO:tensorflow:loss = 0.0007271396, step = 2501 (18.535 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37474\n",
            "INFO:tensorflow:loss = 0.00064825156, step = 2601 (18.604 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.14946\n",
            "INFO:tensorflow:loss = 0.00067271123, step = 2701 (19.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.39538\n",
            "INFO:tensorflow:loss = 0.0006255156, step = 2801 (18.533 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37228\n",
            "INFO:tensorflow:loss = 0.00063146115, step = 2901 (18.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.34715\n",
            "INFO:tensorflow:loss = 0.00059260725, step = 3001 (18.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.40098\n",
            "INFO:tensorflow:loss = 0.00054549664, step = 3101 (18.515 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.38272\n",
            "INFO:tensorflow:loss = 0.0005246951, step = 3201 (18.577 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3297 into /tmp/tmpxlbzj587/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 5.30851\n",
            "INFO:tensorflow:loss = 0.0005104592, step = 3301 (18.841 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.38101\n",
            "INFO:tensorflow:loss = 0.00047736353, step = 3401 (18.581 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.38033\n",
            "INFO:tensorflow:loss = 0.00048217515, step = 3501 (18.587 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.27661\n",
            "INFO:tensorflow:loss = 0.0004918384, step = 3601 (18.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36392\n",
            "INFO:tensorflow:loss = 0.00046943326, step = 3701 (18.644 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35401\n",
            "INFO:tensorflow:loss = 0.0004373476, step = 3801 (18.680 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.3505\n",
            "INFO:tensorflow:loss = 0.00043696052, step = 3901 (18.691 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.30936\n",
            "INFO:tensorflow:loss = 0.00038485604, step = 4001 (18.831 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.33871\n",
            "INFO:tensorflow:loss = 0.0003892812, step = 4101 (18.734 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.33823\n",
            "INFO:tensorflow:loss = 0.00035865756, step = 4201 (18.731 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.17455\n",
            "INFO:tensorflow:loss = 0.0003826905, step = 4301 (19.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.23425\n",
            "INFO:tensorflow:loss = 0.0003601807, step = 4401 (19.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.32707\n",
            "INFO:tensorflow:loss = 0.00036890633, step = 4501 (18.775 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.29436\n",
            "INFO:tensorflow:loss = 0.00035640146, step = 4601 (18.887 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37662\n",
            "INFO:tensorflow:loss = 0.00034375332, step = 4701 (18.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.40188\n",
            "INFO:tensorflow:loss = 0.00031852207, step = 4801 (18.511 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35161\n",
            "INFO:tensorflow:loss = 0.0003316578, step = 4901 (18.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.32693\n",
            "INFO:tensorflow:loss = 0.00030330088, step = 5001 (18.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35555\n",
            "INFO:tensorflow:loss = 0.0003124032, step = 5101 (18.676 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.3148\n",
            "INFO:tensorflow:loss = 0.00028622776, step = 5201 (18.814 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.40085\n",
            "INFO:tensorflow:loss = 0.00028276656, step = 5301 (18.517 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.41655\n",
            "INFO:tensorflow:loss = 0.00024939748, step = 5401 (18.463 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.3396\n",
            "INFO:tensorflow:loss = 0.0002707578, step = 5501 (18.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35053\n",
            "INFO:tensorflow:loss = 0.0003373365, step = 5601 (18.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35572\n",
            "INFO:tensorflow:loss = 0.00026466523, step = 5701 (18.672 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35967\n",
            "INFO:tensorflow:loss = 0.00024940283, step = 5801 (18.659 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.31161\n",
            "INFO:tensorflow:loss = 0.0002537485, step = 5901 (18.830 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.06608\n",
            "INFO:tensorflow:loss = 0.0002469323, step = 6001 (19.735 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.30454\n",
            "INFO:tensorflow:loss = 0.00025741739, step = 6101 (18.852 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.32058\n",
            "INFO:tensorflow:loss = 0.0002395805, step = 6201 (18.795 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.3198\n",
            "INFO:tensorflow:loss = 0.00026776883, step = 6301 (18.797 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.38039\n",
            "INFO:tensorflow:loss = 0.00024737164, step = 6401 (18.586 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6492 into /tmp/tmpxlbzj587/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 5.19293\n",
            "INFO:tensorflow:loss = 0.00022375016, step = 6501 (19.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.32984\n",
            "INFO:tensorflow:loss = 0.00022108767, step = 6601 (18.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.32\n",
            "INFO:tensorflow:loss = 0.00023267142, step = 6701 (18.798 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.28888\n",
            "INFO:tensorflow:loss = 0.00022899517, step = 6801 (18.908 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.31088\n",
            "INFO:tensorflow:loss = 0.00021439235, step = 6901 (18.829 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.39016\n",
            "INFO:tensorflow:loss = 0.00020905137, step = 7001 (18.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.34711\n",
            "INFO:tensorflow:loss = 0.00020505802, step = 7101 (18.699 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36548\n",
            "INFO:tensorflow:loss = 0.00020147362, step = 7201 (18.640 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.33846\n",
            "INFO:tensorflow:loss = 0.00018673972, step = 7301 (18.729 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.33357\n",
            "INFO:tensorflow:loss = 0.000196261, step = 7401 (18.750 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.34758\n",
            "INFO:tensorflow:loss = 0.00017317523, step = 7501 (18.699 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.26451\n",
            "INFO:tensorflow:loss = 0.00019753796, step = 7601 (19.000 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.19828\n",
            "INFO:tensorflow:loss = 0.00019168152, step = 7701 (19.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35214\n",
            "INFO:tensorflow:loss = 0.00019743394, step = 7801 (18.686 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36749\n",
            "INFO:tensorflow:loss = 0.00017474298, step = 7901 (18.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37326\n",
            "INFO:tensorflow:loss = 0.00017123956, step = 8001 (18.613 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.34617\n",
            "INFO:tensorflow:loss = 0.00020097733, step = 8101 (18.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.32116\n",
            "INFO:tensorflow:loss = 0.00017830441, step = 8201 (18.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35796\n",
            "INFO:tensorflow:loss = 0.00017287402, step = 8301 (18.664 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.3299\n",
            "INFO:tensorflow:loss = 0.0001726802, step = 8401 (18.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.28152\n",
            "INFO:tensorflow:loss = 0.00015949045, step = 8501 (18.930 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35461\n",
            "INFO:tensorflow:loss = 0.00016921473, step = 8601 (18.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36756\n",
            "INFO:tensorflow:loss = 0.00017371071, step = 8701 (18.631 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35742\n",
            "INFO:tensorflow:loss = 0.0001576156, step = 8801 (18.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37329\n",
            "INFO:tensorflow:loss = 0.0001640395, step = 8901 (18.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35986\n",
            "INFO:tensorflow:loss = 0.00016681911, step = 9001 (18.652 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36217\n",
            "INFO:tensorflow:loss = 0.00016888518, step = 9101 (18.650 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.35477\n",
            "INFO:tensorflow:loss = 0.00015801155, step = 9201 (18.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.11572\n",
            "INFO:tensorflow:loss = 0.00015032927, step = 9301 (19.547 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.34124\n",
            "INFO:tensorflow:loss = 0.0001534813, step = 9401 (18.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.40723\n",
            "INFO:tensorflow:loss = 0.00014233134, step = 9501 (18.495 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36488\n",
            "INFO:tensorflow:loss = 0.00015870403, step = 9601 (18.638 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9690 into /tmp/tmpxlbzj587/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 5.24375\n",
            "INFO:tensorflow:loss = 0.0001460664, step = 9701 (19.072 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.3343\n",
            "INFO:tensorflow:loss = 0.00014047945, step = 9801 (18.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36718\n",
            "INFO:tensorflow:loss = 0.00015228364, step = 9901 (18.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.34674\n",
            "INFO:tensorflow:loss = 0.0001376723, step = 10001 (18.703 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10100 into /tmp/tmpxlbzj587/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.00014342238.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.estimator.Estimator at 0x7f3fb4e41fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "metadata": {
        "id": "9qrqkKF757e-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "463143b3-ff9c-43f0-fd1d-18a3bef9071b"
      },
      "cell_type": "code",
      "source": [
        "ranker.model_dir"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp/tmpxlbzj587'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {
        "id": "bdJEYY7G7rjg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = '/tmp/tmpxlbzj587'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "# ! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# ! unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQwGGJxd81zr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "b1d6eda8-e2eb-46b1-a3d6-2e445de7e809"
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://d5f572f4.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}