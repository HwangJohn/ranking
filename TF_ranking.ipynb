{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-ranking.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "DwZbuwtxoAzD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### https://github.com/tensorflow/ranking\n",
        "\n",
        "블로그 : https://ai.googleblog.com/2018/12/tf-ranking-scalable-tensorflow-library.html"
      ]
    },
    {
      "metadata": {
        "id": "77RHdyJQWkPO",
        "colab_type": "code",
        "outputId": "2d6bfb87-aa89-4015-d1ac-af467296234a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "cell_type": "code",
      "source": [
        "# code download\n",
        "!git clone https://github.com/tensorflow/ranking.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ranking'...\n",
            "remote: Enumerating objects: 157, done.\u001b[K\n",
            "Receiving objects:   0% (1/157)   \rReceiving objects:   1% (2/157)   \rReceiving objects:   2% (4/157)   \rReceiving objects:   3% (5/157)   \rReceiving objects:   4% (7/157)   \rReceiving objects:   5% (8/157)   \rReceiving objects:   6% (10/157)   \rReceiving objects:   7% (11/157)   \rReceiving objects:   8% (13/157)   \rReceiving objects:   9% (15/157)   \rReceiving objects:  10% (16/157)   \rReceiving objects:  11% (18/157)   \rReceiving objects:  12% (19/157)   \rReceiving objects:  13% (21/157)   \rReceiving objects:  14% (22/157)   \rReceiving objects:  15% (24/157)   \rReceiving objects:  16% (26/157)   \rReceiving objects:  17% (27/157)   \rReceiving objects:  18% (29/157)   \rReceiving objects:  19% (30/157)   \rReceiving objects:  20% (32/157)   \rReceiving objects:  21% (33/157)   \rReceiving objects:  22% (35/157)   \rReceiving objects:  23% (37/157)   \rReceiving objects:  24% (38/157)   \rReceiving objects:  25% (40/157)   \rReceiving objects:  26% (41/157)   \rReceiving objects:  27% (43/157)   \rReceiving objects:  28% (44/157)   \rReceiving objects:  29% (46/157)   \rReceiving objects:  30% (48/157)   \rReceiving objects:  31% (49/157)   \rReceiving objects:  32% (51/157)   \rReceiving objects:  33% (52/157)   \rReceiving objects:  34% (54/157)   \rReceiving objects:  35% (55/157)   \rReceiving objects:  36% (57/157)   \rReceiving objects:  37% (59/157)   \rReceiving objects:  38% (60/157)   \rReceiving objects:  39% (62/157)   \rReceiving objects:  40% (63/157)   \rReceiving objects:  41% (65/157)   \rReceiving objects:  42% (66/157)   \rReceiving objects:  43% (68/157)   \rReceiving objects:  44% (70/157)   \rReceiving objects:  45% (71/157)   \rReceiving objects:  46% (73/157)   \rReceiving objects:  47% (74/157)   \rReceiving objects:  48% (76/157)   \rReceiving objects:  49% (77/157)   \rReceiving objects:  50% (79/157)   \rReceiving objects:  51% (81/157)   \rReceiving objects:  52% (82/157)   \rremote: Total 157 (delta 0), reused 0 (delta 0), pack-reused 157\u001b[K\n",
            "Receiving objects:  53% (84/157)   \rReceiving objects:  54% (85/157)   \rReceiving objects:  55% (87/157)   \rReceiving objects:  56% (88/157)   \rReceiving objects:  57% (90/157)   \rReceiving objects:  58% (92/157)   \rReceiving objects:  59% (93/157)   \rReceiving objects:  60% (95/157)   \rReceiving objects:  61% (96/157)   \rReceiving objects:  62% (98/157)   \rReceiving objects:  63% (99/157)   \rReceiving objects:  64% (101/157)   \rReceiving objects:  65% (103/157)   \rReceiving objects:  66% (104/157)   \rReceiving objects:  67% (106/157)   \rReceiving objects:  68% (107/157)   \rReceiving objects:  69% (109/157)   \rReceiving objects:  70% (110/157)   \rReceiving objects:  71% (112/157)   \rReceiving objects:  72% (114/157)   \rReceiving objects:  73% (115/157)   \rReceiving objects:  74% (117/157)   \rReceiving objects:  75% (118/157)   \rReceiving objects:  76% (120/157)   \rReceiving objects:  77% (121/157)   \rReceiving objects:  78% (123/157)   \rReceiving objects:  79% (125/157)   \rReceiving objects:  80% (126/157)   \rReceiving objects:  81% (128/157)   \rReceiving objects:  82% (129/157)   \rReceiving objects:  83% (131/157)   \rReceiving objects:  84% (132/157)   \rReceiving objects:  85% (134/157)   \rReceiving objects:  86% (136/157)   \rReceiving objects:  87% (137/157)   \rReceiving objects:  88% (139/157)   \rReceiving objects:  89% (140/157)   \rReceiving objects:  90% (142/157)   \rReceiving objects:  91% (143/157)   \rReceiving objects:  92% (145/157)   \rReceiving objects:  93% (147/157)   \rReceiving objects:  94% (148/157)   \rReceiving objects:  95% (150/157)   \rReceiving objects:  96% (151/157)   \rReceiving objects:  97% (153/157)   \rReceiving objects:  98% (154/157)   \rReceiving objects:  99% (156/157)   \rReceiving objects: 100% (157/157)   \rReceiving objects: 100% (157/157), 131.68 KiB | 5.49 MiB/s, done.\n",
            "Resolving deltas:   0% (0/86)   \rResolving deltas:   2% (2/86)   \rResolving deltas:  23% (20/86)   \rResolving deltas:  30% (26/86)   \rResolving deltas:  33% (29/86)   \rResolving deltas:  40% (35/86)   \rResolving deltas:  45% (39/86)   \rResolving deltas:  46% (40/86)   \rResolving deltas:  47% (41/86)   \rResolving deltas:  48% (42/86)   \rResolving deltas:  52% (45/86)   \rResolving deltas:  53% (46/86)   \rResolving deltas:  58% (50/86)   \rResolving deltas:  59% (51/86)   \rResolving deltas:  60% (52/86)   \rResolving deltas:  61% (53/86)   \rResolving deltas:  62% (54/86)   \rResolving deltas:  65% (56/86)   \rResolving deltas:  67% (58/86)   \rResolving deltas:  70% (61/86)   \rResolving deltas:  72% (62/86)   \rResolving deltas:  74% (64/86)   \rResolving deltas:  75% (65/86)   \rResolving deltas:  81% (70/86)   \rResolving deltas:  82% (71/86)   \rResolving deltas:  84% (73/86)   \rResolving deltas:  87% (75/86)   \rResolving deltas:  88% (76/86)   \rResolving deltas:  91% (79/86)   \rResolving deltas:  94% (81/86)   \rResolving deltas:  95% (82/86)   \rResolving deltas:  96% (83/86)   \rResolving deltas:  97% (84/86)   \rResolving deltas:  98% (85/86)   \rResolving deltas: 100% (86/86)   \rResolving deltas: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YCF4wk0da5iA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## bazel install for building tf-ranking package\n",
        "\n",
        "https://stackoverflow.com/questions/45767275/unable-to-install-bazel-on-ubuntu-14-04-using-apt-get 참조\n"
      ]
    },
    {
      "metadata": {
        "id": "_eGTxyusXLx8",
        "colab_type": "code",
        "outputId": "8c1ec41e-db18-46bc-bc1b-e3583a5a148f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3573
        }
      },
      "cell_type": "code",
      "source": [
        "# install bazel\n",
        "!apt-get install pkg-config zip g++ zlib1g-dev unzip python\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/0.20.0/bazel-0.20.0-installer-linux-x86_64.sh\n",
        "!chmod +x bazel-0.20.0-installer-linux-x86_64.sh\n",
        "!./bazel-0.20.0-installer-linux-x86_64.sh --user"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu2).\n",
            "python is already the newest version (2.7.15~rc1-1).\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "zip is already the newest version (3.0-11build1).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "zlib1g-dev set to manually installed.\n",
            "g++ is already the newest version (4:7.3.0-3ubuntu2.1).\n",
            "g++ set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n",
            "--2019-03-19 00:25:49--  https://github.com/bazelbuild/bazel/releases/download/0.20.0/bazel-0.20.0-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/16e3fc80-f4b8-11e8-9fbb-d3e0922a0573?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190319%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190319T002549Z&X-Amz-Expires=300&X-Amz-Signature=353d8bdb4391a57247fb4f661fde19435db3a9720ec75c59fb8d38c8114493a5&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.20.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-03-19 00:25:49--  https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/16e3fc80-f4b8-11e8-9fbb-d3e0922a0573?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190319%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190319T002549Z&X-Amz-Expires=300&X-Amz-Signature=353d8bdb4391a57247fb4f661fde19435db3a9720ec75c59fb8d38c8114493a5&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.20.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.104.203\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.104.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170853024 (163M) [application/octet-stream]\n",
            "Saving to: ‘bazel-0.20.0-installer-linux-x86_64.sh’\n",
            "\n",
            "bazel-0.20.0-instal 100%[===================>] 162.94M  96.4MB/s    in 1.7s    \n",
            "\n",
            "2019-03-19 00:25:50 (96.4 MB/s) - ‘bazel-0.20.0-installer-linux-x86_64.sh’ saved [170853024/170853024]\n",
            "\n",
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# Release 0.20.0 (2018-11-30)\n",
            "\n",
            "Baseline: 7bf7f031c332dc483257248d1c1f98ad75bbc83b\n",
            "\n",
            "Cherry picks:\n",
            "\n",
            "   + fd52341505e725487c6bc6dfbe6b5e081aa037da:\n",
            "     update bazel-toolchains pin to latest release Part of changes to\n",
            "     allow bazelci to use 0.19.0 configs. RBE toolchain configs at or\n",
            "     before 0.17.0 are not compatible with bazel 0.19.0 or above.\n",
            "   + 241f28d05424db2d11ee245dc856b992258505e3:\n",
            "     Revert \"Toggle --incompatible_disable_late_bound_option_defaults\n",
            "     flag.\"\n",
            "   + f7e5aef145c33968f658eb2260e25630dc41cc67:\n",
            "     Add cc_toolchain targets for the new entries in the default\n",
            "     cc_toolchain_suite.\n",
            "   + d2920e32ec7f3f8551a693d33c17b19f1b802145:\n",
            "     Revert \"WindowsFileSystem: open files with delete-sharing\"\n",
            "\n",
            "[Breaking changes in 0.20](https://github.com/bazelbuild/bazel/issues?q=is%3Aissue+label%3Abreaking-change-0.20)\n",
            "\n",
            "  - [--incompatible_remove_native_http_archive](https://github.com/bazelbuild/bazel/issues/6570).\n",
            "  - [--incompatible_remove_native_git_repository](https://github.com/bazelbuild/bazel/issues/6569).\n",
            "  - [--incompatible_disable_cc_toolchain_label_from_crosstool_proto](https://github.com/bazelbuild/bazel/issues/6434).\n",
            "  - [--incompatible_disable_depset_in_cc_user_flags](https://github.com/bazelbuild/bazel/issues/6384).\n",
            "  - [--incompatible_disable_cc_configuration_make_variables](https://github.com/bazelbuild/bazel/issues/6381).\n",
            "  - [--incompatible_disallow_conflicting_providers](https://github.com/bazelbuild/bazel/issues/5902).\n",
            "  - [--incompatible_range_type](https://github.com/bazelbuild/bazel/issues/5264).\n",
            "\n",
            "[0.20 is a migration window for the following changes](https://github.com/bazelbuild/bazel/issues?q=is%3Aissue+label%3Amigration-0.20)\n",
            "\n",
            "  - [--incompatible_use_jdk10_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6661)\n",
            "  - [--incompatible_use_remotejdk_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6656)\n",
            "  - [--incompatible_disable_sysroot_from_configuration](https://github.com/bazelbuild/bazel/issues/6565)\n",
            "  - [--incompatible_provide_cc_toolchain_info_from_cc_toolchain_suite](https://github.com/bazelbuild/bazel/issues/6537)\n",
            "  - [--incompatible_disable_depset_in_cc_user_flags](https://github.com/bazelbuild/bazel/issues/6383)\n",
            "  - [--incompatible_package_name_is_a_function](https://github.com/bazelbuild/bazel/issues/5827)\n",
            "\n",
            "[Breaking changes in the next release (0.21)](https://github.com/bazelbuild/bazel/issues?q=is%3Aissue+label%3Abreaking-change-0.21)\n",
            "\n",
            "  - [--incompatible_use_jdk10_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6661)\n",
            "  - [--incompatible_use_remotejdk_as_host_javabase](https://github.com/bazelbuild/bazel/issues/6656)\n",
            "  - [--incompatible_disable_sysroot_from_configuration](https://github.com/bazelbuild/bazel/issues/6565)\n",
            "  - [--incompatible_provide_cc_toolchain_info_from_cc_toolchain_suite](https://github.com/bazelbuild/bazel/issues/6537)\n",
            "  - [--incompatible_disable_depset_in_cc_user_flags](https://github.com/bazelbuild/bazel/issues/6383)\n",
            "  - [--incompatible_disallow_data_transition](https://github.com/bazelbuild/bazel/issues/6153)\n",
            "  - [--incompatible_package_name_is_a_function](https://github.com/bazelbuild/bazel/issues/5827)\n",
            "  - [--incompatible_disallow_slash_operator](https://github.com/bazelbuild/bazel/issues/5823)\n",
            "  - [--incompatible_static_name_resolution](https://github.com/bazelbuild/bazel/issues/5637)\n",
            "\n",
            "Incompatible changes:\n",
            "\n",
            "  - the --experimental_no_dotd_scanning_with_modules command line\n",
            "    argument is not supported anymore.\n",
            "  - The --prune_cpp_modules command line option is not supported\n",
            "    anymore.\n",
            "  - the --experimental_prune_cpp_input_discovery command line option\n",
            "    is not supported anymore.\n",
            "\n",
            "New features:\n",
            "\n",
            "  - Added support for Android NDK r18.\n",
            "\n",
            "Important changes:\n",
            "\n",
            "  - The 'default' parameter of attr.output and attr.output_list is\n",
            "    removed. This is controlled by\n",
            "    --incompatible_no_output_attr_default\n",
            "  - A number of platform-related Starlark APIs which were previously\n",
            "    marked \"experimental\" are now disabled by default, and may be\n",
            "    enabled via --experimental_platforms_api\n",
            "  - Make legacy-test-support (\"legacy_test-<api-level>\") from\n",
            "    android_sdk_repository neverlink. The legacy test support\n",
            "    libraries shouldn't be built into test binaries. To make them\n",
            "    available at runtime, developers should declare them via\n",
            "    uses-library:\n",
            "    https://developer.android.com/training/testing/set-up-project#andr\n",
            "    oid-test-base\n",
            "  - query remote server Capabilities (per REAPI v2)\n",
            "  - CppRules: All cc_toolchains depended on from\n",
            "    cc_toolchain_suite.toolchains are now analyzed when not using\n",
            "    platforms in order to select the right cc_toolchain.\n",
            "  - removed obsolete --explicit_jre_deps flag.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_cpp_toolchain_skylark_api was\n",
            "    flipped.\n",
            "  - Improve error messaging when unsupport proguard options are\n",
            "    specified at the library level.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_cpp_toolchain_skylark_api was\n",
            "    flipped.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_cpp_toolchain_skylark_api was\n",
            "    flipped.\n",
            "  - The --incompatible_disable_late_bound_option_defaults flag has\n",
            "    been flipped (#6384)\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_legacy_flags_cc_toolchain_api was flipped\n",
            "    (#6434)\n",
            "  - Fixed issue where ctx.resolve_command created conflicting\n",
            "    intermediate files when resolve_command was called multiple times\n",
            "    within the same rule invocation with a long command attribute.\n",
            "  - Incompatible flag\n",
            "    --incompatible_disable_cc_configuration_make_variables was\n",
            "    flipped (#6381)\n",
            "  - If the --javabase flag is unset, it Bazel locates a JDK using\n",
            "    the JAVA_HOME environment variable and searching the PATH. If no\n",
            "    JDK is found --javabase will be empty, and builds targeting Java\n",
            "    will not\n",
            "    be supported. Previously Bazel would fall back to using the\n",
            "    embedded\n",
            "    JDK as a --javabase, but this is no longer default behaviour. A\n",
            "    JDK should\n",
            "    be explicitly installed instead to enable Java development\n",
            "  - Bazel will now shut down when idle for 5 minutes and the system\n",
            "    is low on RAM (linux only).\n",
            "  - CROSSTOOL file is now read from the package of cc_toolchain, not\n",
            "    from\n",
            "    the package of cc_toolchain_suite. This is not expected to break\n",
            "    anybody since\n",
            "    cc_toolchain_suite and cc_toolchain are commonly in the same\n",
            "    package.\n",
            "  - All overrides of Starlark's ctx.new_file function are now\n",
            "    deprecated.\n",
            "      Try the `--incompatible_new_actions_api` flag to ensure your\n",
            "    code is forward-compatible.\n",
            "  - --incompatible_disable_cc_toolchain_label_from_crosstool_proto\n",
            "    was flipped.\n",
            "  - Introduce --(no)shutdown_on_low_sys_mem startup flag to toggle\n",
            "    idle low-memory shutdown, disabled by default.\n",
            "  - --incompatible_disable_cc_toolchain_label_from_crosstool_proto\n",
            "    was flipped.\n",
            "  - --incompatible_disable_cc_toolchain_label_from_crosstool_proto\n",
            "    was flipped.\n",
            "  - CppRules: All cc_toolchains depended on from\n",
            "    cc_toolchain_suite.toolchains are now analyzed when not using\n",
            "    platforms in order to select the right cc_toolchain.\n",
            "  - The function `attr.license` is deprecated and will be removed.\n",
            "      It can be disabled now with `--incompatible_no_attr_license`.\n",
            "  - `range()` function now returns a lazy value\n",
            "    (`--incompatible_range_type` is now set by default).\n",
            "  - The code coverage report now includes the actual paths to header\n",
            "    files instead of the ugly,\n",
            "    Bazel generated, virtual includes path.\n",
            "  - `--incompatible_disallow_conflicting_providers` has been switched\n",
            "    to true\n",
            "  - Add new flag `--incompatible_disable_systool_from_configration` to\n",
            "    disable loading the systool from CppConfiguration.\n",
            "  - Add new flag `--incompatible_disable_sysroot_from_configuration`\n",
            "    to\n",
            "    disable loading the systool from CppConfiguration.\n",
            "  - Sorting remote Platform properties for remote execution. May\n",
            "    affect cache keys!\n",
            "  - Use different server log files per Bazel server process; java.log\n",
            "    is\n",
            "    now a symlink to the latest log.\n",
            "\n",
            "This release contains contributions from many people at Google, as well as a7g4 <a7g4@a7g4.net>, Alan <alan.agius@betssongroup.com>, Asaf Flescher <asafflesch@gmail.com>, Benjamin Peterson <bp@benjamin.pe>, Ed Schouten <ed.schouten@prodrive-technologies.com>, George Gensure <ggensure@uber.com>, George Kalpakas <kalpakas.g@gmail.com>, Greg <gregestren@users.noreply.github.com>, Irina Iancu <iirina@users.noreply.github.com>, Keith Smiley <keithbsmiley@gmail.com>, Loo Rong Jie <loorongjie@gmail.com>, Mark Zeren <mzeren@vmware.com>, Petros Eskinder <petroseskinder@users.noreply.github.com>, rachcatch <rachelcatchpoole@hotmail.com>, Robert Brown <robert.brown@gmail.com>, Robert Gay <robert.gay@redfin.com>, Salty Egg <2281521+zhouhao@users.noreply.github.com>.\n",
            "\n",
            "## Build informations\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/2987897)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/root/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /root/.bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e6w2zj-TV17d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "6062d38c-a9e1-4f17-eb77-f4ecc59cd7d0"
      },
      "cell_type": "code",
      "source": [
        "!ls ranking"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTING.md  LICENSE  README.md  tensorflow_ranking  WORKSPACE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PtRTbi9GahZN",
        "colab_type": "code",
        "outputId": "ea7baeca-04b0-4b11-fe46-99a9fb96c63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4063
        }
      },
      "cell_type": "code",
      "source": [
        "# building tf-ranking package\n",
        "import os\n",
        "os.environ['PATH']\n",
        "os.environ['PATH'] = os.environ['PATH']+\":$HOME/bin\"\n",
        "!export PATH=\"$PATH:$HOME/bin\"\n",
        "!apt-get install python-pip\n",
        "\n",
        "!cd ranking  && $HOME/bin/bazel build tensorflow_ranking/tools/pip_package:build_pip_package\n",
        "!cd ranking  && tensorflow_ranking/tools/pip_package/build_pip_package.sh /tmp/ranking_pip\n",
        "!pip install /tmp/ranking_pip/tensorflow_ranking*.whl"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip-whl python-pkg-resources python-secretstorage\n",
            "  python-setuptools python-six python-wheel python-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python-cryptography-vectors\n",
            "  python-dbus-dbg python-dbus-doc python-enum34-doc python-gi-cairo\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-fs\n",
            "  python-gdata python-keyczar python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip python-pip-whl python-pkg-resources\n",
            "  python-secretstorage python-setuptools python-six python-wheel python-xdg\n",
            "0 upgraded, 22 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 3,376 kB of archives.\n",
            "After this operation, 10.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.2 [221 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dbus amd64 1.2.6-1 [90.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-secretstorage all 2.3.1-2 [11.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyring all 10.6.0-1 [30.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyrings.alt all 3.0-1 [16.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1 [1,652 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip all 9.0.1-2.3~ubuntu1 [151 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-setuptools all 39.0.1-2 [329 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-wheel all 0.30.0-0.2 [36.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-xdg all 0.25-4ubuntu1 [31.3 kB]\n",
            "Fetched 3,376 kB in 1s (3,335 kB/s)\n",
            "Selecting previously unselected package libpython-all-dev:amd64.\n",
            "(Reading database ... 131323 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all.\n",
            "Preparing to unpack .../01-python-all_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all-dev.\n",
            "Preparing to unpack .../02-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-crypto.\n",
            "Preparing to unpack .../05-python-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../06-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../07-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../08-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../10-python-cryptography_2.1.4-1ubuntu1.2_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.2) ...\n",
            "Selecting previously unselected package python-dbus.\n",
            "Preparing to unpack .../11-python-dbus_1.2.6-1_amd64.deb ...\n",
            "Unpacking python-dbus (1.2.6-1) ...\n",
            "Selecting previously unselected package python-gi.\n",
            "Preparing to unpack .../12-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python-secretstorage.\n",
            "Preparing to unpack .../13-python-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python-keyring.\n",
            "Preparing to unpack .../14-python-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python-keyrings.alt.\n",
            "Preparing to unpack .../15-python-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../16-python-pip-whl_9.0.1-2.3~ubuntu1_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1) ...\n",
            "Selecting previously unselected package python-pip.\n",
            "Preparing to unpack .../17-python-pip_9.0.1-2.3~ubuntu1_all.deb ...\n",
            "Unpacking python-pip (9.0.1-2.3~ubuntu1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../18-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-setuptools.\n",
            "Preparing to unpack .../19-python-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python-wheel.\n",
            "Preparing to unpack .../20-python-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python-xdg.\n",
            "Preparing to unpack .../21-python-xdg_0.25-4ubuntu1_all.deb ...\n",
            "Unpacking python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python-wheel (0.30.0-0.2) ...\n",
            "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up python-dbus (1.2.6-1) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-pip (9.0.1-2.3~ubuntu1) ...\n",
            "Setting up python-all (2.7.15~rc1-1) ...\n",
            "Setting up python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-setuptools (39.0.1-2) ...\n",
            "Setting up python-keyrings.alt (3.0-1) ...\n",
            "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.2) ...\n",
            "Setting up python-secretstorage (2.3.1-2) ...\n",
            "Setting up python-keyring (10.6.0-1) ...\n",
            "Extracting Bazel installation...\n",
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "Starting local Bazel server and connecting to it...\n",
            "\u001b[32mINFO: \u001b[0mInvocation ID: 4214b5ca-9cae-4d2f-963b-7e892be274d3\n",
            "\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (1 \\\n",
            "packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (2 \\\n",
            "packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (2 \\\n",
            "packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (2 \\\n",
            "packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (2 \\\n",
            "packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (3 \\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (3 \\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (4 \\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (11\\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow_ranking/tools/pip_package:build_pip_package (14\\\n",
            "\u001b[32mINFO: \u001b[0mAnalysed target //tensorflow_ranking/tools/pip_package:build_pip_package (14 packages loaded, 113 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 1 target...\n",
            "Target //tensorflow_ranking/tools/pip_package:build_pip_package up-to-date:\n",
            "  bazel-bin/tensorflow_ranking/tools/pip_package/build_pip_package\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 12.331s, Critical Path: 0.04s\n",
            "\u001b[32mINFO: \u001b[0m0 processes.\n",
            "\u001b[32mINFO:\u001b[0m Build completed successfully, 4 total actions\n",
            "\u001b[0mTue Mar 19 00:27:19 UTC 2019 : === Preparing sources in dir: /tmp/tmp.144PsQDEjF\n",
            "Tue Mar 19 00:27:19 UTC 2019 : === Building wheel\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/tensorflow_ranking\n",
            "copying tensorflow_ranking/__init__.py -> build/lib/tensorflow_ranking\n",
            "creating build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/feature.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/data.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/metrics.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/head.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/losses.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/utils.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/__init__.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/version.py -> build/lib/tensorflow_ranking/python\n",
            "copying tensorflow_ranking/python/model.py -> build/lib/tensorflow_ranking/python\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/wheel\n",
            "creating build/bdist.linux-x86_64/wheel/tensorflow_ranking\n",
            "copying build/lib/tensorflow_ranking/__init__.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking\n",
            "creating build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/feature.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/data.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/metrics.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/head.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/losses.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/utils.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/__init__.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/version.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "copying build/lib/tensorflow_ranking/python/model.py -> build/bdist.linux-x86_64/wheel/tensorflow_ranking/python\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating tensorflow_ranking.egg-info\n",
            "writing tensorflow_ranking.egg-info/PKG-INFO\n",
            "writing dependency_links to tensorflow_ranking.egg-info/dependency_links.txt\n",
            "writing requirements to tensorflow_ranking.egg-info/requires.txt\n",
            "writing top-level names to tensorflow_ranking.egg-info/top_level.txt\n",
            "writing manifest file 'tensorflow_ranking.egg-info/SOURCES.txt'\n",
            "reading manifest file 'tensorflow_ranking.egg-info/SOURCES.txt'\n",
            "writing manifest file 'tensorflow_ranking.egg-info/SOURCES.txt'\n",
            "Copying tensorflow_ranking.egg-info to build/bdist.linux-x86_64/wheel/tensorflow_ranking-0.1.1-py3.6.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.linux-x86_64/wheel/tensorflow_ranking-0.1.1.dist-info/WHEEL\n",
            "creating 'dist/tensorflow_ranking-0.1.1-py2.py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'tensorflow_ranking/__init__.py'\n",
            "adding 'tensorflow_ranking/python/__init__.py'\n",
            "adding 'tensorflow_ranking/python/data.py'\n",
            "adding 'tensorflow_ranking/python/feature.py'\n",
            "adding 'tensorflow_ranking/python/head.py'\n",
            "adding 'tensorflow_ranking/python/losses.py'\n",
            "adding 'tensorflow_ranking/python/metrics.py'\n",
            "adding 'tensorflow_ranking/python/model.py'\n",
            "adding 'tensorflow_ranking/python/utils.py'\n",
            "adding 'tensorflow_ranking/python/version.py'\n",
            "adding 'tensorflow_ranking-0.1.1.dist-info/METADATA'\n",
            "adding 'tensorflow_ranking-0.1.1.dist-info/WHEEL'\n",
            "adding 'tensorflow_ranking-0.1.1.dist-info/top_level.txt'\n",
            "adding 'tensorflow_ranking-0.1.1.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n",
            "Tue Mar 19 00:27:19 UTC 2019 : === Output wheel file is in: /tmp/ranking_pip\n",
            "Processing /tmp/ranking_pip/tensorflow_ranking-0.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-ranking==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-ranking==0.1.1) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-ranking==0.1.1) (1.14.6)\n",
            "Installing collected packages: tensorflow-ranking\n",
            "Successfully installed tensorflow-ranking-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BWPIAhpmbrPA",
        "colab_type": "code",
        "outputId": "3cb8f65b-f311-4bc3-d1b8-b2623d29d14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2638
        }
      },
      "cell_type": "code",
      "source": [
        "# test after installing tf-ranking package\n",
        "!cd ranking && /root/bin/bazel test //tensorflow_ranking/..."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: \u001b[0mInvocation ID: 894463a6-93ce-4333-9d8e-d4551b945482\n",
            "\u001b[32mLoading:\u001b[0m \n",
            "\r\u001b[1A\u001b[K\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
            "\u001b[32mINFO: \u001b[0mAnalysed 21 targets (7 packages loaded, 181 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 13 targets and 8 test targets...\n",
            "\u001b[32m[7 / 9]\u001b[0m 2 actions running\n",
            "    Testing //tensorflow_ranking/python:model_test; 0s processwrapper-sandbox\n",
            "\u001b[32m[7 / 9]\u001b[0m 2 actions running\n",
            "    Testing //tensorflow_ranking/python:model_test; 0s processwrapper-sandbox\n",
            "\u001b[32m[7 / 9]\u001b[0m 2 actions running\n",
            "    Testing //tensorflow_ranking/python:model_test; 1s processwrapper-sandbox\n",
            "\u001b[32m[7 / 9]\u001b[0m 2 actions running\n",
            "    Testing //tensorflow_ranking/python:model_test; 2s processwrapper-sandbox\n",
            "\u001b[32m[7 / 9]\u001b[0m 2 actions running\n",
            "    Testing //tensorflow_ranking/python:model_test; 3s processwrapper-sandbox\n",
            "\u001b[32m[7 / 9]\u001b[0m 2 actions running\n",
            "    Testing //tensorflow_ranking/python:model_test; 4s processwrapper-sandbox\n",
            "\u001b[32m[7 / 9]\u001b[0m 2 actions running\n",
            "    Testing //tensorflow_ranking/python:model_test; 5s processwrapper-sandbox\n",
            "\u001b[32m[7 / 9]\u001b[0m 1 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 6s processwrapper-sandbox\n",
            "\u001b[32m[11 / 13]\u001b[0m 1 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 6s processwrapper-sandbox\n",
            "\u001b[32m[11 / 13]\u001b[0m 1 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 7s processwrapper-sandbox\n",
            "\u001b[32m[11 / 13]\u001b[0m 1 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 8s processwrapper-sandbox\n",
            "\u001b[32m[11 / 13]\u001b[0m 1 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 9s processwrapper-sandbox\n",
            "\u001b[32m[11 / 13]\u001b[0m 1 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:feature_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 10s processwrapper-sandbox\n",
            "\u001b[32m[11 / 13]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:head_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 11s processwrapper-sandbox\n",
            "\u001b[32m[18 / 23]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:head_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 11s processwrapper-sandbox\n",
            "\u001b[32m[18 / 23]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:head_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 12s processwrapper-sandbox\n",
            "\u001b[32m[18 / 23]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:head_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 13s processwrapper-sandbox\n",
            "\u001b[32m[18 / 23]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:head_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 14s processwrapper-sandbox\n",
            "\u001b[32m[18 / 23]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:head_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 15s processwrapper-sandbox\n",
            "\u001b[32m[18 / 23]\u001b[0m 2 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:head_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 16s processwrapper-sandbox\n",
            "\u001b[32m[18 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:model_test; 16s processwrapper-sandbox\n",
            "\u001b[32m[19 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[19 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[19 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[19 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[19 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[19 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[19 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[19 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[20 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions, 1 running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[20 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[20 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[21 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[21 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[21 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[21 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[21 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[21 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[21 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[21 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[21 / 23]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "\u001b[32m[22 / 25]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions, 1 running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "    Testing //.../python:losses_test (shard 3 of 4); 7s processwrapper-sandbox\n",
            "\u001b[32m[25 / 27]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "    Testing //.../python:losses_test (shard 3 of 4); 7s processwrapper-sandbox\n",
            "\u001b[32m[25 / 27]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "    Testing //.../python:losses_test (shard 3 of 4); 8s processwrapper-sandbox\n",
            "\u001b[32m[25 / 27]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "    Testing //.../python:losses_test (shard 3 of 4); 9s processwrapper-sandbox\n",
            "\u001b[32m[25 / 27]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "    //tensorflow_ranking/python:losses_test; 10s processwrapper-sandbox\n",
            "\u001b[32m[25 / 27]\u001b[0m 3 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:model_test\u001b[0m\n",
            "    //tensorflow_ranking/python:losses_test; 11s processwrapper-sandbox\n",
            "\u001b[32m[25 / 27]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:losses_test\u001b[0m\n",
            "    //tensorflow_ranking/python:losses_test; 12s processwrapper-sandbox\n",
            "\u001b[32m[29 / 31]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:losses_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:data_test; 5s processwrapper-sandbox\n",
            "\u001b[32m[29 / 31]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:losses_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:data_test; 6s processwrapper-sandbox\n",
            "\u001b[32m[29 / 31]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:losses_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:data_test; 7s processwrapper-sandbox\n",
            "\u001b[32m[29 / 31]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:losses_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:data_test; 8s processwrapper-sandbox\n",
            "\u001b[32m[29 / 31]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:losses_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:data_test; 9s processwrapper-sandbox\n",
            "\u001b[32m[29 / 31]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:losses_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:data_test; 10s processwrapper-sandbox\n",
            "\u001b[32m[29 / 31]\u001b[0m 4 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:losses_test\u001b[0m\n",
            "    Testing //tensorflow_ranking/python:data_test; 11s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 6s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 6s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 7s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 8s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 9s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 10s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 11s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 12s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 13s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 14s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 15s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 16s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 17s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 5 / 8 tests;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m.../python:data_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 18s processwrapper-sandbox\n",
            "\u001b[32m[30 / 32]\u001b[0m 6 / 8 tests, \u001b[31m\u001b[1m1 failed\u001b[0m;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[31m\u001b[1m..._libsvm_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 19s processwrapper-sandbox\n",
            "\u001b[31m\u001b[1mFAIL: \u001b[0m//tensorflow_ranking/examples:tf_ranking_libsvm_test (see /root/.cache/bazel/_bazel_root/621d00021cbc65de1ea771a5ec34ee2f/execroot/org_tensorflow_ranking/bazel-out/k8-fastbuild/testlogs/tensorflow_ranking/examples/tf_ranking_libsvm_test/test.log)\n",
            "\u001b[32m[30 / 32]\u001b[0m 6 / 8 tests, \u001b[31m\u001b[1m1 failed\u001b[0m;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[31m\u001b[1m..._libsvm_test\u001b[0m\n",
            "    Testing //.../examples:tf_ranking_libsvm_test; 19s processwrapper-sandbox\n",
            "\u001b[32m[34 / 36]\u001b[0m 6 / 8 tests, \u001b[31m\u001b[1m1 failed\u001b[0m;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[31m\u001b[1m..._libsvm_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 13s processwrapper-sandbox\n",
            "\u001b[32m[34 / 36]\u001b[0m 6 / 8 tests, \u001b[31m\u001b[1m1 failed\u001b[0m;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[31m\u001b[1m..._libsvm_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 14s processwrapper-sandbox\n",
            "\u001b[32m[34 / 36]\u001b[0m 7 / 8 tests, \u001b[31m\u001b[1m1 failed\u001b[0m;\u001b[0m 2 actions running\u001b[0m; last test: \u001b[32m...metrics_test\u001b[0m\n",
            "    Testing //.../python:metrics_test; 15s processwrapper-sandbox\n",
            "\u001b[32m[38 / 39]\u001b[0m 7 / 8 tests, \u001b[31m\u001b[1m1 failed\u001b[0m;\u001b[0m  1 action\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\u001b[0m\n",
            "\u001b[32m[38 / 39]\u001b[0m 7 / 8 tests, \u001b[31m\u001b[1m1 failed\u001b[0m;\u001b[0m  1 action\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\u001b[0m\n",
            "\u001b[32m[38 / 39]\u001b[0m 7 / 8 tests, \u001b[31m\u001b[1m1 failed\u001b[0m;\u001b[0m  1 action\u001b[0m; last test: \u001b[32m.../python:metrics_test\u001b[0m\u001b[0m\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 64.609s, Critical Path: 19.68s\n",
            "\u001b[32mINFO: \u001b[0m11 processes: 11 processwrapper-sandbox.\n",
            "\u001b[32mINFO:\u001b[0m Build completed, 1 test FAILED, 39 total actions\n",
            "//tensorflow_ranking/python:data_test                                    \u001b[0m\u001b[32mPASSED\u001b[0m in 11.5s\n",
            "//tensorflow_ranking/python:feature_test                                 \u001b[0m\u001b[32mPASSED\u001b[0m in 6.2s\n",
            "//tensorflow_ranking/python:head_test                                    \u001b[0m\u001b[32mPASSED\u001b[0m in 4.9s\n",
            "//tensorflow_ranking/python:metrics_test                                 \u001b[0m\u001b[32mPASSED\u001b[0m in 15.3s\n",
            "//tensorflow_ranking/python:model_test                                   \u001b[0m\u001b[32mPASSED\u001b[0m in 16.8s\n",
            "//tensorflow_ranking/python:utils_test                                   \u001b[0m\u001b[32mPASSED\u001b[0m in 4.5s\n",
            "//tensorflow_ranking/examples:tf_ranking_libsvm_test                     \u001b[0m\u001b[31m\u001b[1mFAILED\u001b[0m in 19.6s\n",
            "  /root/.cache/bazel/_bazel_root/621d00021cbc65de1ea771a5ec34ee2f/execroot/org_tensorflow_ranking/bazel-out/k8-fastbuild/testlogs/tensorflow_ranking/examples/tf_ranking_libsvm_test/test.log\n",
            "//tensorflow_ranking/python:losses_test                                  \u001b[0m\u001b[32mPASSED\u001b[0m in 15.1s\n",
            "  Stats over 4 runs: max = 15.1s, min = 8.3s, avg = 11.3s, dev = 2.8s\n",
            "\n",
            "Executed 8 out of 8 tests: 7 tests pass and \u001b[0m\u001b[31m\u001b[1m1 fails locally\u001b[0m.\n",
            "\u001b[32mINFO:\u001b[0m Build completed, 1 test FAILED, 39 total actions\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gzQRTlN_eUiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python -c \"import tensorflow_ranking\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lEyf-VNFLg93",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train test"
      ]
    },
    {
      "metadata": {
        "id": "eZ5spDZdeZ1l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.environ['OUTPUT_DIR']=\"/tmp/output\"\n",
        "os.environ['TRAIN']=\"ranking/tensorflow_ranking/examples/data/train.txt\"\n",
        "os.environ['VALI']=\"ranking/tensorflow_ranking/examples/data/vali.txt \"\n",
        "os.environ['TEST']=\"ranking/tensorflow_ranking/examples/data/test.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i0SJYOXOheU1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf $OUTPUT_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vuFE8M4jgEoO",
        "colab_type": "code",
        "outputId": "5e23a8bc-3ec1-49ee-b782-318a587543d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "cell_type": "code",
      "source": [
        "!/root/bin/bazel build -c opt ranking/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "ERROR: The 'build' command is only supported from within a workspace.\n",
            "WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\n",
            "INFO: Invocation ID: dcd4aa9a-289f-4af9-956a-b456536d2267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cg0B0LCPhqy2",
        "colab_type": "code",
        "outputId": "55b23d8f-60ee-490d-f069-7d10fc0984ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2009
        }
      },
      "cell_type": "code",
      "source": [
        "!ranking/bazel-bin/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary \\\n",
        "  --train_path=$TRAIN \\\n",
        "  --vali_path=$VALI \\\n",
        "  --test_path=$TEST \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --num_features=136 \\\n",
        "  --num_train_steps=100"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loading data from ranking/tensorflow_ranking/examples/data/train.txt\n",
            "INFO:tensorflow:Number of queries: 27\n",
            "INFO:tensorflow:Number of documents in total: 119\n",
            "INFO:tensorflow:Number of documents discarded: 0\n",
            "INFO:tensorflow:Loading data from ranking/tensorflow_ranking/examples/data/vali.txt\n",
            "INFO:tensorflow:Number of queries: 9\n",
            "INFO:tensorflow:Number of documents in total: 36\n",
            "INFO:tensorflow:Number of documents discarded: 0\n",
            "INFO:tensorflow:Loading data from ranking/tensorflow_ranking/examples/data/test.txt\n",
            "INFO:tensorflow:Number of queries: 9\n",
            "INFO:tensorflow:Number of documents in total: 36\n",
            "INFO:tensorflow:Number of documents discarded: 0\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4f49f45eb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function make_groupwise_ranking_fn.<locals>._model_fn at 0x7f4f4a33c950>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "WARNING:tensorflow:From /content/ranking/bazel-bin/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary.runfiles/org_tensorflow_ranking/tensorflow_ranking/python/model.py:102: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/ranking/bazel-bin/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary.runfiles/org_tensorflow_ranking/tensorflow_ranking/examples/tf_ranking_libsvm.py:231: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /content/ranking/bazel-bin/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary.runfiles/org_tensorflow_ranking/tensorflow_ranking/examples/tf_ranking_libsvm.py:239: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.batch_normalization instead.\n",
            "WARNING:tensorflow:From /content/ranking/bazel-bin/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary.runfiles/org_tensorflow_ranking/tensorflow_ranking/examples/tf_ranking_libsvm.py:241: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /content/ranking/bazel-bin/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary.runfiles/org_tensorflow_ranking/tensorflow_ranking/examples/tf_ranking_libsvm.py:247: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/ranking/bazel-bin/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary.runfiles/org_tensorflow_ranking/tensorflow_ranking/python/model.py:268: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2019-03-19 00:29:20.512892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-03-19 00:29:20.513247: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x227d9c0 executing computations on platform Host. Devices:\n",
            "2019-03-19 00:29:20.513289: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-03-19 00:29:20.606360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-03-19 00:29:20.606888: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x227dde0 executing computations on platform CUDA. Devices:\n",
            "2019-03-19 00:29:20.606927: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-03-19 00:29:20.607307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-03-19 00:29:20.607355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-03-19 00:29:22.137431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-03-19 00:29:22.137495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-03-19 00:29:22.137515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-03-19 00:29:22.137794: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-03-19 00:29:22.137893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/output/model.ckpt.\n",
            "2019-03-19 00:29:25.973855: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "INFO:tensorflow:loss = 1.3632654, step = 0\n",
            "INFO:tensorflow:Saving checkpoints for 100 into /tmp/output/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "WARNING:tensorflow:From /content/ranking/bazel-bin/tensorflow_ranking/examples/tf_ranking_libsvm_py_binary.runfiles/org_tensorflow_ranking/tensorflow_ranking/python/metrics.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-03-19T00:29:33Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2019-03-19 00:29:33.462560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-03-19 00:29:33.462634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-03-19 00:29:33.462661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-03-19 00:29:33.462679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-03-19 00:29:33.462959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/output/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/1]\n",
            "INFO:tensorflow:Finished evaluation at 2019-03-19-00:29:34\n",
            "INFO:tensorflow:Saving dict for global step 100: global_step = 100, labels_mean = 0.7777778, logits_mean = 0.28530055, loss = 0.90951, metric/arp = 3.142857, metric/ndcg@1 = 0.6296297, metric/ndcg@10 = 0.8327359, metric/ndcg@3 = 0.76187724, metric/ndcg@5 = 0.79245925, metric/ordered_pair_accuracy = 0.5423729\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/output/model.ckpt-100\n",
            "INFO:tensorflow:Loss for final step: 0.035427086.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-03-19T00:29:37Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2019-03-19 00:29:38.009554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-03-19 00:29:38.009637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-03-19 00:29:38.009664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-03-19 00:29:38.009686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-03-19 00:29:38.009967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /tmp/output/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-03-19-00:29:38\n",
            "INFO:tensorflow:Saving dict for global step 100: global_step = 100, labels_mean = 0.7777778, logits_mean = 0.28530055, loss = 0.90951, metric/arp = 3.142857, metric/ndcg@1 = 0.6296297, metric/ndcg@10 = 0.8327359, metric/ndcg@3 = 0.76187724, metric/ndcg@5 = 0.79245925, metric/ordered_pair_accuracy = 0.5423729\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/output/model.ckpt-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IrhGlyFxqBAZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook example practice"
      ]
    },
    {
      "metadata": {
        "id": "sOxgfUIQjEPH",
        "colab_type": "code",
        "outputId": "d479291b-7f19-4400-b4b6-60bb986935cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_ranking as tfr\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.executing_eagerly()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "1evfHk4XqLlW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we will define some global parameters."
      ]
    },
    {
      "metadata": {
        "id": "iuQwhiLjqJSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store the paths to files containing training and test instances.\n",
        "# As noted above, we will assume the data is in the LibSVM format\n",
        "# and that the content of each file is sorted by query ID.\n",
        "\n",
        "# file path : ranking/tensorflow_ranking/examples\n",
        "\n",
        "_TRAIN_DATA_PATH=\"ranking/tensorflow_ranking/examples/data/train.txt\"\n",
        "_TEST_DATA_PATH=\"ranking/tensorflow_ranking/examples/data/test.txt\"\n",
        "\n",
        "# Define a loss function. To find a complete list of available\n",
        "# loss functions or to learn how to add your own custom function\n",
        "# please refer to the tensorflow_ranking.losses module.\n",
        "_LOSS=\"pairwise_logistic_loss\"\n",
        "\n",
        "# In the TF-Ranking framework, a training instance is represented\n",
        "# by a Tensor that contains features from a list of documents\n",
        "# associated with a single query. For simplicity, we fix the shape\n",
        "# of these Tensors to a maximum list size and call it \"list_size,\"\n",
        "# the maximum number of documents per query in the dataset.\n",
        "# In this demo, we take the following approach:\n",
        "#   * If a query has fewer documents, its Tensor will be padded\n",
        "#     appropriately.\n",
        "#   * If a query has more documents, we shuffle its list of\n",
        "#     documents and trim the list down to the prescribed list_size.\n",
        "_LIST_SIZE=100\n",
        "\n",
        "# The total number of features per query-document pair.\n",
        "# We set this number to the number of features in the MSLR-Web30K\n",
        "# dataset.\n",
        "_NUM_FEATURES=136\n",
        "\n",
        "# Parameters to the scoring function.\n",
        "_BATCH_SIZE=32\n",
        "_HIDDEN_LAYER_DIMS=[\"20\", \"10\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfX9601xsHez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input Pipeline\n",
        "\n",
        "첫 번째 단계는 데이터 집합을 읽는 입력 파이프 라인을 만들고 tensorflow.data.Dataset 개체를 생성합니다. 이 예제에서는 주어진 파일에서 Dataset을 생성하기 위해 tensorflow_ranking.data 모듈에 포함 된 LibSVM 파서를 호출합니다.\n",
        "\n",
        "이 함수를 경로 인수로 매개 변수화하여 함수가 학습 및 테스트 데이터 파일을 읽는 데 사용될 수 있도록합니다."
      ]
    },
    {
      "metadata": {
        "id": "0egAEH5msGZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn(path):\n",
        "  train_dataset = tf.data.Dataset.from_generator(\n",
        "      tfr.data.libsvm_generator(path, _NUM_FEATURES, _LIST_SIZE),\n",
        "      output_types=(\n",
        "          {str(k): tf.float32 for k in range(1,_NUM_FEATURES+1)},\n",
        "          tf.float32\n",
        "      ),\n",
        "      output_shapes=(\n",
        "          {str(k): tf.TensorShape([_LIST_SIZE, 1])\n",
        "            for k in range(1,_NUM_FEATURES+1)},\n",
        "          tf.TensorShape([_LIST_SIZE])\n",
        "      )\n",
        "  )\n",
        "\n",
        "  train_dataset = train_dataset.shuffle(1000).repeat().batch(_BATCH_SIZE)\n",
        "  return train_dataset.make_one_shot_iterator().get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6QkRWZptKcD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Scoring Function\n",
        "\n",
        "다음으로, 우리는 틀림없이 TF 랭킹 모델의 중심에있는 Scoring function 으로 돌아갑니다. 아이디어는 (일련의) 쿼리 - 문서 쌍 (들)에 대한 관련성 점수를 계산하는 것입니다. TF- 랭킹 모델은 훈련 데이터를 사용하여이 기능을 학습합니다.\n",
        "여기에서는 피드 포워드 네트워크를 사용하여 채점 함수를 공식화합니다. 함수는 단일 example (즉, 질의 - 문서 쌍)의 특징을 취하여 관련도를 산출한다."
      ]
    },
    {
      "metadata": {
        "id": "gP4CGFo4tKEh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def example_feature_columns():\n",
        "  \"\"\"Returns the example feature columns.\"\"\"\n",
        "  feature_names = [\n",
        "      \"%d\" % (i+1) for i in range(0, _NUM_FEATURES)\n",
        "  ]\n",
        "  return {\n",
        "      name: tf.feature_column.numeric_column(\n",
        "        name, shape=(1,), default_value=0.0) for name in feature_names\n",
        "  }\n",
        "\n",
        "def make_score_fn():\n",
        "  \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
        "\n",
        "  def _score_fn(context_features, group_features, mode, params, config):\n",
        "    \"\"\"Defines the network to score a documents.\"\"\"\n",
        "    del params\n",
        "    del config\n",
        "    # Define input layer.\n",
        "    example_input = [\n",
        "        tf.layers.flatten(group_features[name])\n",
        "        for name in sorted(example_feature_columns())\n",
        "    ]\n",
        "    input_layer = tf.concat(example_input, 1)\n",
        "\n",
        "    cur_layer = input_layer\n",
        "    for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
        "      cur_layer = tf.layers.dense(\n",
        "          cur_layer,\n",
        "          units=layer_width,\n",
        "          activation=\"tanh\")\n",
        "\n",
        "    logits = tf.layers.dense(cur_layer, units=1)\n",
        "    return logits\n",
        "\n",
        "  return _score_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZTXgBKM3iaA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics\n",
        "\n",
        "우리는 TF 랭킹 라이브러리에서 인기있는 정보 검색 평가 메트릭을 구현했습니다."
      ]
    },
    {
      "metadata": {
        "id": "VHc_8FvitJRX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_metric_fns():\n",
        "  \"\"\"Returns a dict from name to metric functions.\n",
        "\n",
        "  This can be customized as follows. Care must be taken when handling padded\n",
        "  lists.\n",
        "\n",
        "  def _auc(labels, predictions, features):\n",
        "    is_label_valid = tf_reshape(tf.greater_equal(labels, 0.), [-1, 1])\n",
        "    clean_labels = tf.boolean_mask(tf.reshape(labels, [-1, 1], is_label_valid)\n",
        "    clean_pred = tf.boolean_maks(tf.reshape(predictions, [-1, 1], is_label_valid)\n",
        "    return tf.metrics.auc(clean_labels, tf.sigmoid(clean_pred), ...)\n",
        "  metric_fns[\"auc\"] = _auc\n",
        "\n",
        "  Returns:\n",
        "    A dict mapping from metric name to a metric function with above signature.\n",
        "  \"\"\"\n",
        "  metric_fns = {}\n",
        "  metric_fns.update({\n",
        "      \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
        "          tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
        "      for topn in [1, 3, 5, 10]\n",
        "  })\n",
        "\n",
        "  return metric_fns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnQmzk964eEB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Putting It All Together\n",
        "\n",
        "우리는 이제 위의 모든 구성 요소를 함께 모으고 모델을 훈련하고 평가하는 데 사용할 수있는 Estimator를 만들 준비가되었습니다."
      ]
    },
    {
      "metadata": {
        "id": "fkPp6cBj4c9L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_estimator(hparams):\n",
        "  \"\"\"Create a ranking estimator.\n",
        "\n",
        "  Args:\n",
        "    hparams: (tf.contrib.training.HParams) a hyperparameters object.\n",
        "\n",
        "  Returns:\n",
        "    tf.learn `Estimator`.\n",
        "  \"\"\"\n",
        "  def _train_op_fn(loss):\n",
        "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
        "    return tf.contrib.layers.optimize_loss(\n",
        "        loss=loss,\n",
        "        global_step=tf.train.get_global_step(),\n",
        "        learning_rate=hparams.learning_rate,\n",
        "        optimizer=\"Adagrad\")\n",
        "\n",
        "  ranking_head = tfr.head.create_ranking_head(\n",
        "      loss_fn=tfr.losses.make_loss_fn(_LOSS),\n",
        "      eval_metric_fns=eval_metric_fns(),\n",
        "      train_op_fn=_train_op_fn)\n",
        "\n",
        "  return tf.estimator.Estimator(\n",
        "      model_fn=tfr.model.make_groupwise_ranking_fn(\n",
        "          group_score_fn=make_score_fn(),\n",
        "          group_size=1,\n",
        "          transform_fn=None,\n",
        "          ranking_head=ranking_head),\n",
        "      params=hparams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d50zp4i65r6b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "위에 정의한 Estimator를 인스턴스화하고 초기화합니다"
      ]
    },
    {
      "metadata": {
        "id": "M8CV3TCm5rHI",
        "colab_type": "code",
        "outputId": "bad0f4aa-8c61-4ccf-934b-1a0a663d43c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "cell_type": "code",
      "source": [
        "hparams = tf.contrib.training.HParams(learning_rate=0.05)\n",
        "ranker = get_estimator(hparams)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpr344uc3r\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpr344uc3r', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f110359e780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "91OQL-Zb51hW",
        "colab_type": "code",
        "outputId": "cae02a34-0514-4381-87ec-9d8a17d7d16c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1176
        }
      },
      "cell_type": "code",
      "source": [
        "ranker.train(input_fn=lambda: input_fn(_TRAIN_DATA_PATH), steps=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, use\n",
            "    tf.py_function, which takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    \n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Use groupwise dnn v2.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_ranking/python/model.py:102: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From <ipython-input-16-236a4621764a>:21: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-16-236a4621764a>:30: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_ranking/python/model.py:268: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpr344uc3r/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.005109, step = 0\n",
            "INFO:tensorflow:global_step/sec: 8.24387\n",
            "INFO:tensorflow:loss = 0.055475887, step = 100 (12.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.68396\n",
            "INFO:tensorflow:loss = 0.019521972, step = 200 (11.517 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.5651\n",
            "INFO:tensorflow:loss = 0.011096195, step = 300 (11.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.66734\n",
            "INFO:tensorflow:loss = 0.0063614566, step = 400 (11.538 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.51969\n",
            "INFO:tensorflow:loss = 0.005132134, step = 500 (11.738 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.64386\n",
            "INFO:tensorflow:loss = 0.0045031705, step = 600 (11.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.64314\n",
            "INFO:tensorflow:loss = 0.0032739139, step = 700 (11.572 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.44397\n",
            "INFO:tensorflow:loss = 0.003042591, step = 800 (11.839 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.59622\n",
            "INFO:tensorflow:loss = 0.0024982346, step = 900 (11.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.5994\n",
            "INFO:tensorflow:loss = 0.0019884277, step = 1000 (11.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.62204\n",
            "INFO:tensorflow:loss = 0.0018988692, step = 1100 (11.594 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.49812\n",
            "INFO:tensorflow:loss = 0.001725496, step = 1200 (11.771 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.49882\n",
            "INFO:tensorflow:loss = 0.0014863838, step = 1300 (11.768 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.5191\n",
            "INFO:tensorflow:loss = 0.0013457991, step = 1400 (11.740 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.54176\n",
            "INFO:tensorflow:loss = 0.0011796174, step = 1500 (11.704 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.60616\n",
            "INFO:tensorflow:loss = 0.0011551214, step = 1600 (11.617 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9qrqkKF757e-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ranker.model_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdJEYY7G7rjg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = '/tmp/tmpxlbzj587'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "# ! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# ! unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQwGGJxd81zr",
        "colab_type": "code",
        "outputId": "b1d6eda8-e2eb-46b1-a3d6-2e445de7e809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://d5f572f4.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}